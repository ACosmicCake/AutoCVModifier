import sqlite3
import json
from datetime import datetime, date # Ensure date is also imported

DATABASE_NAME = 'instance/jobs.db'

# Helper function for JSON serialization with date/datetime handling
def json_serial(obj):
    """JSON serializer for objects not serializable by default json code"""
    if isinstance(obj, (datetime, date)): # Handles both datetime.datetime and datetime.date
        return obj.isoformat()
    # Add handling for other non-serializable types if necessary in the future
    # For example, if jobspy returns other complex types not handled by default.
    # However, be cautious about overly broad try-except blocks or stringifying unknown types.
    # It's often better to explicitly handle known non-serializable types.
    raise TypeError (f"Type {type(obj)} not serializable for JSON")

def get_db_connection(db_path=None):
    """Establishes a connection to the SQLite database.
    Uses db_path if provided, otherwise defaults to DATABASE_NAME.
    """
    path_to_connect = db_path if db_path is not None else DATABASE_NAME
    conn = sqlite3.connect(path_to_connect)
    conn.row_factory = sqlite3.Row  # Allows accessing columns by name
    return conn

def init_db(db_path=None):
    """Initializes the database and creates tables if they don't exist."""
    conn = get_db_connection(db_path=db_path)
    cursor = conn.cursor()

    # Enable Foreign Key support for SQLite
    cursor.execute("PRAGMA foreign_keys = ON;")

    cursor.execute('''
        CREATE TABLE IF NOT EXISTS jobs (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            title TEXT NOT NULL,
            company TEXT,
            location TEXT,
            description TEXT,
            url TEXT UNIQUE NOT NULL,
            source TEXT NOT NULL,
            date_scraped TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP,
            raw_job_data TEXT,
            -- applied: INTEGER, 0 for false (CV not generated), 1 for true (CV generated for this job).
            applied INTEGER NOT NULL DEFAULT 0
        )
    ''')
    # Commit the CREATE TABLE statement
    conn.commit()

    # Attempt to add the 'applied' column if it doesn't exist (for existing databases)
    # This is a common pattern for simple schema migrations in SQLite.
    # The meaning of 'applied' is now 'cv_generated'.
    try:
        # Check if the column exists before trying to add it, to avoid error if already run
        # A more robust migration strategy would be needed for production apps.
        cursor.execute("PRAGMA table_info(jobs);")
        columns = [column[1] for column in cursor.fetchall()]
        if 'applied' not in columns:
            cursor.execute("ALTER TABLE jobs ADD COLUMN applied INTEGER NOT NULL DEFAULT 0;")
            conn.commit() # Commit the ALTER TABLE statement
            print("Column 'applied' (meaning CV generated) added to 'jobs' table.")
        else:
            # If it exists, we assume its meaning is updated (documentation change)
            print("Column 'applied' (meaning CV generated) already exists in 'jobs' table.")
    except sqlite3.OperationalError as e:
        # This might catch other OperationalErrors if PRAGMA fails, though unlikely here.
        print(f"An SQLite OperationalError occurred during 'applied' column check/add: {e}")
        # Depending on the error, might not want to raise, or handle more specifically.
        # For "duplicate column name" specifically (if previous check failed to prevent it), it's not critical.
        if "duplicate column name: applied" not in str(e).lower():
            raise # Re-raise if it's not a 'duplicate column' error

    # -- generated_cvs Table --
    # Stores metadata about each tailored CV generated by the system.
    # - id: Primary key.
    # - job_id: Foreign key to the 'jobs' table, linking the CV to a specific job.
    #           Can be NULL if the CV wasn't for a job stored in the 'jobs' table.
    # - generated_pdf_filename: The filename of the PDF stored in the instance folder.
    # - tailored_cv_json_content: The full JSON string of the tailored CV.
    # - generation_timestamp: When the CV was generated.
    cursor.execute('''
        CREATE TABLE IF NOT EXISTS generated_cvs (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            job_id INTEGER,
            generated_pdf_filename TEXT NOT NULL,
            tailored_cv_json_content TEXT NOT NULL,
            generation_timestamp TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP,
            FOREIGN KEY (job_id) REFERENCES jobs (id) ON DELETE CASCADE
        )
    ''')
    conn.commit()
    print("Table 'generated_cvs' initialized or already exists.")

    conn.close()
    print("Database initialized: 'jobs' and 'generated_cvs' tables schema updated (if necessary).")

def save_job(job_data, db_path=None):
    """Saves a single job listing to the database.
    Handles duplicates based on the URL.
    """
    conn = get_db_connection(db_path=db_path)
    cursor = conn.cursor()

    # Prepare data for insertion
    # Ensure all expected keys are present, providing defaults if necessary.

    # Serialize raw_job_data with custom date/datetime handler
    # The 'raw_job_data' key in job_data should ideally hold the original dict from scraper.
    # If not, the whole job_data is used as a fallback.
    data_to_serialize_for_raw_json = job_data.get('raw_job_data', job_data)
    try:
        # Use the json_serial helper as the default for json.dumps
        raw_job_json_string = json.dumps(data_to_serialize_for_raw_json, default=json_serial)
    except TypeError as e:
        # This catch block is a fallback if json_serial itself can't handle a type
        # and raises TypeError, or if another unexpected serialization issue occurs.
        print(f"Error serializing raw_job_data for job URL {job_data.get('url')}: {e}. Storing as basic JSON object.")
        # Store a minimal representation or an error marker.
        # Storing the original job_data might also fail if it contains the problematic type.
        # A simple placeholder indicating serialization failure:
        raw_job_json_string = json.dumps({"error": "raw_job_data serialization failed", "details": str(e)})


    data_to_insert = (
        job_data.get('title'),
        job_data.get('company'),
        job_data.get('location'),
        job_data.get('description'),
        job_data.get('url'),
        job_data.get('source'),
        datetime.now(),  # date_scraped is always set to current timestamp on save
        raw_job_json_string # Use the safely serialized string
    )

    try:
        cursor.execute('''
            INSERT INTO jobs (title, company, location, description, url, source, date_scraped, raw_job_data)
            VALUES (?, ?, ?, ?, ?, ?, ?, ?)
            ON CONFLICT(url) DO NOTHING
        ''', data_to_insert)
        conn.commit()
        if cursor.rowcount > 0:
            print(f"Job saved: {job_data.get('title')} at {job_data.get('company')}")
        else:
            print(f"Job already exists (or error): {job_data.get('title')} at {job_data.get('company')}")
    except sqlite3.Error as e:
        print(f"Database error while saving job {job_data.get('url')}: {e}")
    finally:
        if conn: # Ensure connection exists before trying to close on error
            conn.close()

def toggle_cv_generated_status(job_id: int, db_path=None) -> dict | None:
    """Toggles the 'CV generated' status (column 'applied') of a job (0 to 1 or 1 to 0).

    Args:
        job_id: The ID of the job to update.
        db_path: Optional path to the database file.

    Returns:
        A dictionary containing the job_id and the new 'applied' status (0 or 1) if successful,
        None if the job_id is not found.
    Raises:
        sqlite3.Error: For database related errors during the transaction.
    """
    conn = get_db_connection(db_path=db_path)
    cursor = conn.cursor()

    try:
        # Fetch the current 'applied' status
        cursor.execute("SELECT applied FROM jobs WHERE id = ?", (job_id,))
        job = cursor.fetchone()

        if job is None:
            conn.close()
            return None # Job not found

        current_status = job['applied']
        new_status = 1 - current_status # Toggle logic (0 becomes 1, 1 becomes 0)

        # Update the 'applied' status
        cursor.execute("UPDATE jobs SET applied = ? WHERE id = ?", (new_status, job_id))
        conn.commit()

        conn.close()
        print(f"CV generated status for job_id {job_id} toggled to {new_status}.")
        return {"id": job_id, "applied": new_status} # 'applied' column still named 'applied'

    except sqlite3.Error as e:
        # Rollback in case of error if 'conn' was opened with a transaction context manager,
        # but here we are manually committing. If an error occurs before commit, nothing is saved.
        # If after commit (unlikely here for a simple update), it's already committed.
        # For more complex transactions, explicit rollback might be needed.
        print(f"Database error toggling CV generated status for job {job_id}: {e}")
        if conn: # Ensure connection exists before trying to close
            conn.close()
        raise # Re-raise the exception to be handled by the caller (API endpoint)

def set_job_cv_generated_status(job_id: int, status: bool, db_path: str | None = None) -> bool:
    """Sets the 'CV generated' status (column 'applied') for a given job_id.

    Args:
        job_id: The ID of the job to update.
        status: True to mark as 'CV generated' (1), False otherwise (0).
        db_path (optional): Path to the SQLite database file.

    Returns:
        True if the update was successful (row was found and updated), False otherwise.
    """
    conn = get_db_connection(db_path=db_path)
    cursor = conn.cursor()
    new_status_int = 1 if status else 0
    try:
        cursor.execute("UPDATE jobs SET applied = ? WHERE id = ?", (new_status_int, job_id))
        conn.commit()
        if cursor.rowcount > 0:
            print(f"Set 'CV generated' status to {new_status_int} for job_id {job_id}.")
            return True
        else:
            # This case means the job_id was not found, so no update occurred.
            print(f"Job ID {job_id} not found. 'CV generated' status not updated.")
            return False
    except sqlite3.Error as e:
        print(f"Database error setting 'CV generated' status for job {job_id}: {e}")
        return False
    finally:
        if conn:
            conn.close()

def get_job_by_id(job_id: int, db_path=None):
    """Fetches a single job by its ID from the database."""
    conn = get_db_connection(db_path=db_path)
    cursor = conn.cursor()
    # Ensure all relevant columns are selected, similar to get_jobs
    cursor.execute("SELECT id, title, company, location, description, url, source, date_scraped, applied FROM jobs WHERE id = ?", (job_id,))
    job = cursor.fetchone()
    conn.close()
    if job:
        return dict(job) # Convert sqlite3.Row to dict
    return None

def save_generated_cv(job_id: int | None, pdf_filename: str, tailored_cv_json_string: str, db_path: str | None = None) -> int | None:
    """Saves metadata of a generated CV to the generated_cvs table.

    Args:
        job_id: The ID of the job this CV was tailored for (can be None).
        pdf_filename: The filename of the generated PDF.
        tailored_cv_json_string: The JSON string content of the tailored CV.
        db_path (optional): Path to the SQLite database file. Uses default if None.

    Returns:
        The ID of the newly inserted row, or None if an error occurred.
    """
    conn = get_db_connection(db_path=db_path)
    cursor = conn.cursor()
    sql_statement = '''
        INSERT INTO generated_cvs (job_id, generated_pdf_filename, tailored_cv_json_content)
        VALUES (?, ?, ?);
    '''
    data_to_insert = (job_id, pdf_filename, tailored_cv_json_string)

    try:
        cursor.execute(sql_statement, data_to_insert)
        conn.commit()
        new_id = cursor.lastrowid
        print(f"Generated CV data saved for job_id {job_id}, filename {pdf_filename}. New ID: {new_id}")
        return new_id
    except sqlite3.Error as e:
        print(f"Database error while saving generated CV for job_id {job_id}, filename {pdf_filename}: {e}")
        return None
    finally:
        if conn:
            conn.close()

if __name__ == '__main__':
    # For testing or manual initialization
    init_db()
    # Example usage:
    # test_job = {
    #     'title': 'Software Engineer',
    #     'company': 'Tech Co',
    #     'location': 'Remote',
    #     'description': 'Develop amazing software.',
    #     'url': 'http://example.com/job/123',
    #     'source': 'example_source',
    #     'raw_job_data': {'detail': 'more details here'}
    # }
    # save_job(test_job)
    # test_job_2 = { # Duplicate URL
    #     'title': 'Software Engineer II',
    #     'company': 'Tech Co',
    #     'location': 'Remote',
    #     'description': 'Develop amazing software, now with more experience.',
    #     'url': 'http://example.com/job/123',
    #     'source': 'example_source_new',
    #     'raw_job_data': {'detail': 'even more details here'}
    # }
    # save_job(test_job_2)

def get_jobs(filters=None, db_path=None):
    """Fetches jobs from the database based on provided filters.

    Args:
        filters (dict, optional): A dictionary where keys are column names
                                  and values are the values to filter by.
                                  Special filter 'keyword' searches title and description.
                                  Defaults to None (fetch all jobs).

    Returns:
        list: A list of job dictionaries, or an empty list if no jobs found or error.
    """
    conn = get_db_connection(db_path=db_path)
    cursor = conn.cursor()

    # Update base_query to include the new 'applied' column
    base_query = "SELECT id, title, company, location, description, url, source, date_scraped, applied FROM jobs"
    where_clauses = []
    params = []

    if filters:
        keyword = filters.get('keyword')
        location = filters.get('location')
        source = filters.get('source')
        applied_status = filters.get('applied_status')

        if keyword:
            where_clauses.append("(title LIKE ? OR description LIKE ?)")
            params.extend([f"%{keyword}%", f"%{keyword}%"])

        if location:
            where_clauses.append("location LIKE ?")
            params.append(f"%{location}%")

        if source:
            where_clauses.append("source = ?")
            params.append(source)

        if applied_status == 'applied':
            where_clauses.append("applied = 1")
        elif applied_status == 'not_applied':
            where_clauses.append("applied = 0")
        # If applied_status is 'all', None, or any other value, do not add a filter for 'applied' status

    if where_clauses:
        query = f"{base_query} WHERE {' AND '.join(where_clauses)}"
    else:
        query = base_query

    query += " ORDER BY date_scraped DESC" # Always order by most recent

    try:
        cursor.execute(query, params)
        jobs = cursor.fetchall() # fetchall() returns a list of Row objects
        # Convert Row objects to dictionaries
        jobs_list = [dict(job) for job in jobs]
        return jobs_list
    except sqlite3.Error as e:
        print(f"Database error while fetching jobs: {e}")
        return [] # Return empty list on error
    finally:
        conn.close()

def get_generated_cvs_history(limit=50, db_path=None):
    """Fetches the history of generated CVs, joined with job details.

    Args:
        limit (int, optional): The maximum number of records to fetch. Defaults to 50.
        db_path (str, optional): Path to the SQLite database file.

    Returns:
        list: A list of dictionaries, where each dictionary represents a generated CV record
              joined with its corresponding job details. Returns an empty list on error or if no history.
    """
    conn = get_db_connection(db_path=db_path)
    cursor = conn.cursor()

    query = """
        SELECT
            gc.id AS generated_cv_id,
            gc.job_id,
            gc.generated_pdf_filename,
            gc.tailored_cv_json_content,
            gc.generation_timestamp,
            j.title AS job_title,
            j.company AS job_company,
            j.url AS job_url
        FROM
            generated_cvs gc
        LEFT JOIN
            jobs j ON gc.job_id = j.id
        ORDER BY
            gc.generation_timestamp DESC
        LIMIT ?;
    """
    try:
        cursor.execute(query, (limit,))
        history_rows = cursor.fetchall()
        history_list = [dict(row) for row in history_rows]
        return history_list
    except sqlite3.Error as e:
        print(f"Database error while fetching generated CVs history: {e}")
        return []
    finally:
        if conn:
            conn.close()
